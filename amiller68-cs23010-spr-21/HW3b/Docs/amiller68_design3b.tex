\documentclass[]{article}
%opening
\title{Design Document}
\author{Alex Miller}
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}
\setcounter{secnumdepth}{0}
\usepackage{cancel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[ruled,vlined, linesnumbered]{algorithm2e}
\DontPrintSemicolon


\begin{document}
	\maketitle
	

\section{Modules, data structures, interfaces, invariants:}
Our code base will consist of the following modules:
\begin{itemize}
	\item The highest ranked modules containing C code will be two files -- one called serial.c, the other parallel.c. These modules will, respectively, implement serial and parallel queue performance tests.
	\\\\
	\textbf{serial.c}
	\begin{itemize}
		\item This file will implement the functionality of serial packet and checksum generator performance test, configurable to the following variables:
		\begin{itemize}
			\item M - an integer representing the time in milliseconds that the experiment should run.
			\item n - an integer representing the total number of sources 
			\item W - an integer representing the expected amount of work per packet
			\item U - an char representing a flag specifying what sort of packet distribution to utilize in our tests. $t$ indicates the use of Uniformly Distributed Packets , while $f$ Exponentially Distributed Packets.
			\item s - a non-negative integer, for seeding the packet generator. In practice this will correspond to trial numbers when testing is run.
		\end{itemize}
		\item Using user input, this file will create the specified packet generator. Call this generator $packet\_gen$. It has $n$ sources, a median work value of $W$, and utilizes the seed $s$. 
		\item It will also bind the specified method of extracting packets from $packet\_gen$ to a pointer desginated $packet\_method$ -- the options for packet generators are Uniform and Exponential. 
		\item It will then pass $packet\_gen$, $packet\_method$, as well as any necessary variables to chksum\_serial(); this method generates checksums from $packet\_gen$ from $n$ sources using a average packet size of $W$ and $packet\_method$ for $M$ milliseconds. This method returns an integer, $T$ -- it first describes the number of packets that get fully processed in the allotted time. I will discuss the specifics of this method's implementation below. 
		\item serial.c will finally output $T$ to the terminal, before cleaning up any leftover resources and exiting.
	\end{itemize}
	
	\textbf{parallel.c}
	\begin{itemize}
		\item This file will implement the functionality of parallel packet and checksum generator performance test, configurable to the following variables:
		\begin{itemize}
			\item Like serial.c, this file is configurable to M, n, W, U, and s.
			\item D - an integer representing the depths of the queues to be used in this test
			\item L - a char representing the lock type to be used in our load balancing implementations. Setting this character to t, p, a, and m will direct worker threads to use either our Test and Set, the pthread Mutex, our Anderson's Array, or our MCS lock, respectively, in order to dequeue. The specifics of these lock implementations are discussed below.
			\item S - a char representing a load balancing strategy. Setting this character to L, H, and A will direct our performance test to utilize either a LockFree, HomeQueue, or Awesome load balancing strategy, respectively. The specifics of these different strategies are discussed below.
		\end{itemize}
		\item Using user input, this file will create the specified packet generator. Call this generator $packet\_gen$. It has $n$ sources, a median work value of $W$, and utilizes the seed $s$. 
		\item It will also bind the specified method of extracting packets from $packet\_gen$ to a pointer desginated $packet\_method$. 
		\item Then, parallel.c will initialize a $lock\_t$ instance called $lock$. The $lock\_t$ struct describes an interface for accessing our locking algorithm implementations. This instance will be set to utilize the lock type specified by $L$. This interface is described in the file $lock.c$ and is carried over from assignment 3a.
		\item serial.c will then pass $packet\_gen$, $packet\_method$, $lock$, $S$, as well as any necessary variables to chksum\_parallel(); this method generates checksums from $packet\_gen$ from $n$ sources using a average packet size of $W$ and $packet\_method$ for $M$ milliseconds. This method differs from serial\_packet() in that it utilizes $n$ threads in order to generate checksums, utilizing the load balancing technique specified by $S$. This method returns an integer, $T$ -- it first describes the number of packets that get fully processed in the allotted time. I will discuss the specifics of this method's implementation below. 
		\item parallel.c will finally output $T$ to the terminal, before cleaning up any leftover resources and exiting.
	\end{itemize}
	\item The next level of modules will implement the functionalities of chksum\_serial() and chksum\_parallel(). As such it will be comprised of three files -- chksum.c, queue.c, and lock.c
	\\\\
	\textbf{chksum.c}
	\begin{itemize}
		\item This module will describe chksum\_serial() and chksum\_parallel, the methods that will bs used by serial.c and parallel.c.
		\\\\
		\textbf{long chksum\_serial()}
		\\
		Input:
		\begin{itemize}
			\item PackeSource\_t packet\_gen : a pointer to a packet source
			\item volatile Packet\_t * (*packet\_method)(PacketSource\_t *, int) : a pointer to a method for extracting packets from said source
			\item int n : the number of sources that packets are being generated from
			\item int M : the number of milliseconds this test should run for
		\end{itemize}
		This simply loops through $n$ sources within a non-terminating while loop, utilizing $packet\_method$ to extract new packets from $packet\_gen$. Before this loop begins, a timer is started. At the top of the for-loop, if this timer exceeds $M$ milliseconds, the main thread returns. Otherwise, the loop continues to generate checksums for source $i \in [n]$. Each time the method creates and processes a packet, a counter is incremented, who's final value is returned by this method once it returns from the loop.
		\\\\
		\textbf{long chksum\_parallel()}
		\\
		Input:
		\begin{itemize}
			\item Like chksum\_serial, this method is configurable by $packet\_gen$, $packet\_method$, $n$, and $M$
			\item int D : an integer representing the depths of the queues to be used in this test
			\item L : a char representing the lock type to be used in our load balancing implementations.
			\item S : a char representing a load balancing strategy.
		\end{itemize}
		This method is responsible for initializing the data structures needed for the functioning of $n$ worker threads calculating checksums of packets generated by  $packet\_gen$, extracted by $packet\_method$, and placed in FIFO Lamport queues.
		\\
		Therefore it will allocate space for $n$ instances of the $thread\_args\_t$ data type, which I will describe below. Call this array $T$.
		Following that, it will call create\_queue\_pool(n, D) in order to allocate space for $packet\_queue\_t$ array of size $n$, each with depth $D$. Call this array $Q$. $Q$ represents a pool of Lamport queues.
		\\
		Finally it will allocate an array of $n$ $lock\_t$ instances, all initialized by the lock type specified by $L$. Call this array $L$
		\\
		Following the initialization of these data structures, this method binds the pointer:
		\begin{itemize}
			\item void * (*worker\_method)(void *)
		\end{itemize} 
		to one of three methods describing the following functionalities depending on the specification of $S$. If $S$ is:
		\begin{itemize}
			\item L, then threads should utilize a Lock-Free strategy. This strategy dictates 1 - 1 correspondence between queues and threads, as specified in previous assignment. While a thread's queue has not signaled that it is done queueing new packets, the thread waits until there is a packet in the queue, before dequeueing a packet and processing its checksum. 
			\item H, then threads should utilizes the Home-Queue strategy. This is like the Lock-Free strategy, with the main difference being that, while the Lock-Free strategy does not utilize locking, the Home-Queue threads utilize an array of $n$ locks (initialized in the dispatcher thread), which are in likewise associated in a 1 - 1 correspondence with the $n$ queues in $Q$. Each thread using this strategy locks their queue's lock before calling its dequeue() method, and unlocks it after completing said call.
			\item A, then the threads should utilize my Awesome strategy(!)
		\end{itemize}
		These functionalities will be implemented in $void$ $*L\_worker(void$ $*args)$, $void$ $*H\_worker(void$ $*args)$, $void$ $*A\_worker(void$ $*args)$, respectively. These are the methods that can be bound to $worker\_method$.
		\\
		Each of these functions will take in $thread\_args\_t$ struct with the following attributes:
		\begin{itemize}
			\item int i : an index into the array, $Q$
			\item packet\_t *Q : a pointer to the Lamport queue in $Q$ at index $i$
			\item lock\_t *L : a pointer to a instance of a locking algorithm.
			\item int count : an integer to record a threads throughput. Initially equal to 0, this value should be incremented each time its worker thread generates a checksum.
		\end{itemize}

		The thread this method is called in is the dispatcher thread -- this thread starts $n$ worker threads, which will be responsible for calculating checksums of packets generated by  $packet\_gen$, extracted by $packet\_method$, and placed in $Q$. Each thread will generate checksums in the manner proscribed by $worker\_method$. In order to do this, the dispatcher thread, $\forall i \in [T]$, sets:
		\begin{itemize}
			\item $T[i].i \leftarrow i$
			\item $T[i].Q \leftarrow \&Q[i]$
			\item $T[i].i \leftarrow \$ \&L[i]$
		\end{itemize} 
		and spawns a thread to call $worker\_method$ with $\&T[i]$ as an argument.
		\\\\
		After chksum\_parallel() has initialized and spawned its worker threads and data structures, it carries out a performance test. After starting a timer, it cycles through the $n$ queues in $Q$, each associated with one of $n$ packet sources. One queue at a time, the dispatcher thread will wait until the queue contains space for another packet, write to the queue, and then move on to the next queue. It will repeat this process so long as the timer has been running for less than $M$ milliseconds. Once the timer is up, the dispatcher threads signals all threads to stops, joins them, and adds up the counters stored in the $thread\_args\_t$ instances in $T$. Call this value $C$. This value represents the combined total throughput of all threads over the course of the test.
		\\
		This method terminates by cleaning up the resources initialized above and returning the value stored in $C$.
		
		As such, this method describes neutral interface with which to test the throughput of a dispatcher distributing work among $n$ worker threads, which can be configured to utilize varying and programmable locking algorithms and load balancing strategies.
	\end{itemize}
	\textbf{queue.c}
	\begin{itemize}
		\item This module will describe the construction and functionality of  $packet_queue_t$ struct. This struct implements FIFO Lamport queue. It's declared with the following struct members and methods:
		\begin{itemize}
			\item $head, tail$ : Volatile integers specifying the locations of the head and tail of the queue
			\item $packets$ : a Lamport queue with depth $D$
			\item $done$ : a Volatile boolean designating whether or not we should keep reading from $Q$. This is initially set to $false$
		\end{itemize}
		\item Methods:
		\begin{itemize}
			\item int enq(packet\_queue\_t *Q, volatile Packet\_t x) : queue a $Packet\_t$ instance in the Queue $Q$. Return 1 if $Q$ is full, 0 if otherwise and $x$ was enqueued successfully.
			\item volatile Packet\_t *deq(packet\_queue\_t *Q) : dequeue the next $Packet\_t$ from $Q$. Return a NULL value if the queue is empty
			\item packet\_queue\_t *create\_queue\_pool(int num\_q, int D) : allocate an array of $num\_q$ packet\_queue\_t structs, each of depth $D$
			\item void destroy\_queue\_pool(packet\_queue\_t *Q) : Destroy an array of packet\_queue\_t structs allocated as a block queues
		\end{itemize}
	\end{itemize}
	\textbf{lock.c}
	\begin{itemize}
		\item The locks mentioned above, will be implemented in a file called lock.c. The file will describe the implementation of a Test and Set lock, an Anderson's Array Lock, and an MCS lock, as specified in the textbook and translated into C. The Mutex lock will be called from the pthread library, but wrapped so as to work with our $lock\_t$ interface. The interface has the following attributes associated with it:
		\begin{itemize}
			\item char type : a reference to a lock type, as specified by input
			\item void *l : a pointer to a lock object; this pointer is passed to the initialization, lock, and unlock functions.	
			\item void (*init\_thread)(void *) : This function initializes any thread specific structures required by a lock. It should be called before a thread acquires the lock the first time.	
			\item void (*try\_lock)(void *) : a pointer to the lock's try\_lock function; it throws an exception to the calling thread if the lock object is busy. Otherwise, the calling thread acquires the lock.
			\item void (*lock)(void *) : a pointer to the lock's lock function; it should be called on the void *l (which points to the initialized lock) in order to acquire the lock. 	
			\item void (*unlock)(void *) : a pointer to the lock's unlock function; it should be called on the void *l (which points to the initialized lock) in order to release the lock. 
		\end{itemize}
		\item Each locking algorithm type will have the following methods associated with it:
		\begin{itemize}
			\item init(int n):  initialize a lock to synchronize $n$ threads; $n$ is only used in initializing locks that allocate space for locks prior to use, such as Anderson's lock. Otherwise, $n$ is discarded.
			\item destroy(void *lock): destroy the initialized $lock$ and free any memory allocated to support it
			\item init\_thread(void *lock): in the case of the MCS lock, this method needs to be called by each thread utilizing the lock before it acquires the lock for the first time.
			\item try\_lock(void *lock) : try\_lock $lock$
			\item lock(void *lock): lock $lock$
			\item unlock(void *lock): unlock $lock$
		\end{itemize}
		\item This interface should be able to be initialized and freed either one at a time or as a block. As such, this module will also contain the following methods:
		\begin{itemize}
			\item lock\_t *new\_lock(char type, int n) : initialize a single lock of the kind specified by $type$ which will manage $n$ threads.
			\item lock\_t *new\_lock\_pool(int size, char type, int n) : initialize a lock pool with $size$ locks of the kind specified by $type$, all of which will each manage $n$ threads. This pool is allocated as a block of contiguous memory
			\item int destroy\_lock(lock\_t *L) : destroy a single lock\_t instance
			\item int destroy\_lock\_pool(int size, lock\_t *L) : destroy a pool of contiguously allocated locks of size $size$.
		\end{itemize}
		\item This interface
	\end{itemize}
	\item Our last module consists of testing and analysis protocols, test\_script.sh and analysis.py
	\begin{itemize}
		\item test\_script.sh will consist of a shell script that utilizes serial.c, and parallel.c. This test script will execute these files and record their output, generating experimental data in an automated fashion and storing that data in csv files.

		%State what tests they are going to implement%
	
		\item analysis.py will be responsible for analyzing data, making graphs, and outputting quantitative data to compare the performance of locks.
	\end{itemize}

	\item A note on Invariants... what are they???
\end{itemize}

\section{Test plan:} 
Need to try and come up with issues youre going to run into as you develop...
Do you expect perfroamcen to increase in all test cases?? -- ID which one you suspect
Need to justify how we are delimting time to begin and end, as well as talk about how we are measuring through put with shared timer
should mention that this construction lacks any satisfying way of generating proofs of correctness -- but as the last use of our lamport queue was correct enough -- perhaps the implementations could stand to be tested for definite number of packets, before moving on to throughput tests...

\section{Expected Performance (Performance Hypotheses):}
	
\subsection{Exp}
		
\end{document}
